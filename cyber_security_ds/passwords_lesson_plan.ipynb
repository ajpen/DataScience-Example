{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring Automated SSH Cyber Attacks\n",
        "\n",
        "We'll take a look at some cyber security data gathered by a SSH honeypot. SSH is a protocol for connecting to remote servers on a network, which in this case is the internet. \n",
        "\n",
        "Dataset can be found here: https://www.kaggle.com/lako65/ssh-brute-force-ipuserpassword\n",
        "\n",
        "Lets go ahead and take a look at our dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# We'll set a few global configurations so we can see more rows/columns when we output tables\n",
        "pd.set_option('display.max_rows', 50)\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.width', 100)\n",
        "\n",
        "\n",
        "attacks_df = pd.read_json('brute_force_data.json', orient='records')\n",
        "attacks_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attacks_df.count()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting! So we have the attack location via IP address, the time it occurred and the username/password combinations used for the attack. This dataset can give us some insights on what attackers use often (and what you probably should avoid!)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pay attention to the values in the passwords field. You'll notice that they are in a list format. Data formatted like this isn't intuitive for analytics. Think of it this way: each list is like a table and you end up with a table within a table. Data formatted like this can confuse some querying functions. Lets fix this first."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: \n",
        "In the starting code below, try to flatten the passwords column in the dataframe. Read the comments below or ask questions if you're not sure what to do"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "attack_rows = attacks_df.to_dict(orient='records')\n",
        "\n",
        "attacks_flattened_df = list()\n",
        "for row in attack_rows:\n",
        "  \n",
        "  # row has a dictionary that looks like this {'foreign_ip': 'x.x.x.x', 'passwords': ['password1', 'pass2'], 'timestamp': datetime.object, 'username': 'john'}\n",
        "  if isinstance(row['passwords'], list):\n",
        "    # Try to flatten the rows so that it appears like this instead:\n",
        "    # {'foreign_ip': 'x.x.x.x', 'passwords': 'password1', 'timestamp': datetime.object, 'username': 'john'}\n",
        "    # {'foreign_ip': 'x.x.x.x', 'passwords': 'pass2', 'timestamp': datetime.object, 'username': 'john'}\n",
        "    attacks_flattened_df.append(row)\n",
        "  else:\n",
        "    attacks_flattened_df.append(row)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "attack_rows = attacks_df.to_dict(orient='records')\n",
        "\n",
        "attacks_flattened_df = list()\n",
        "for row in attack_rows:\n",
        "  \n",
        "  # row has a dictionary that looks like this {'foreign_ip': 'x.x.x.x', 'passwords': ['password1', 'pass2'], 'timestamp': datetime.object, 'username': 'john'}\n",
        "  if isinstance(row['passwords'], list):\n",
        "    for pw in row['passwords']:\n",
        "      \n",
        "      # We're gonna copy each row and modify the copy so we don't screw up the original\n",
        "      r = copy.copy(row)\n",
        "      r['password'] = pw\n",
        "      attacks_flattened_df.append(r)\n",
        "  else:\n",
        "    attacks_flattened_df.append(row)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we dont need the passwords list anymore. Lets remove it\n",
        "attacks_flattened_df = pd.DataFrame(attacks_flattened_df)\n",
        "attacks_flattened_df = attacks_flattened_df.drop(columns=\"passwords\")\n",
        "attacks_flattened_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets do some analytics. Looking at our data, we can see that the variables of interest (basically all the variables, except maybe timestamps), are categorical types. Therefore, it would not necessarily help to get the mean, std, percentile, etc for our dataset.\n",
        "\n",
        "We can still try it and see for the fun of it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "attacks_flattened_df.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many unique passwords are in the dataset? Assign your answer to the unique_count variable below then run the cell\n",
        "unique_count = 0 # Replace with your answer\n",
        "print(\"Correct!\" if unique_count == len(attacks_flattened_df['password'].unique()) else \"Try again\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Popular passwords used\n",
        "\n",
        "To get an idea of what passwords were common, we can use a popular data querying function called *Groupby*. *Groupby* aggregates records with identical elements, counting their frequency. here we'll aggregate records with the same password values. We'll then take this count and sort it in descending order."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "attacks_flattened_df.groupby(['password']).count().reset_index().sort_values('foreign_ip', ascending=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cool! Now we know the commonly used passwords for attacks. Should definitely avoid those. Thats not enough though. There are still over 22k unique passwords, and our table doesn't necessarily help. We don't want have to look at all 22k passwords to know which ones we shouldn't use. Wouldn't it be great if you can know how secure a password might be?\n",
        "\n",
        "We can probably do that."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring Passwords\n",
        "\n",
        "\n",
        "Since there are over 22k unique passwords in this dataset, we can have an idea of what they look like by examining their features. Features can be any distinguishing attribute, for example, password length. Below we'll extract a few features and do some statistical analysis on them.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll only be looking at passwords from now on, so we'll create a new dataframe with the passwords column only\n",
        "passwords_df = attacks_flattened_df['password']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of character classes used (uppercase, lowercase, numbers, special \n",
        "# characters) is also a feature, along with the character pool. The character pool is \n",
        "# the list of possible unique characters in the password, depending on the character classes used. \n",
        "\n",
        "# e.g. if an uppercase character is present, a brute force algorithm would need to \n",
        "# check every possible uppercase character; therefore, all uppercase characters are \n",
        "# added to the character pool\n",
        "\n",
        "def count_char_classes(pw):\n",
        "    character_classes = list()\n",
        "    character_classes.append(any([c.islower() for c in pw]))\n",
        "    character_classes.append(any([c.isupper() for c in pw]))\n",
        "    character_classes.append(any([c.isdigit() for c in pw]))\n",
        "    character_classes.append(any([not c.isalpha() and not c.isdigit() for c in pw]))\n",
        "    \n",
        "    return sum(1 if x else 0 for x in character_classes)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the presence of a word can affect the guessability of a password. It might help if we test for that. \n",
        "# Be aware that this function might take a while for the sake of precision\n",
        "\n",
        "# First we need to download an english dictionary\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "\n",
        "from nltk.corpus import words\n",
        "dictionary_index = dict.fromkeys(words.words(), True)\n",
        "\n",
        "def has_word(pw):\n",
        "  # returns true if pw is or contains a dictionary word \n",
        "  return True if dictionary_index.get(pw, None) else False"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also calculate entropy bits, which basically is how unpredictable it is. \n",
        "# To give you an idea of what entropy bits mean, heres an excerpt From Wikipedia: \n",
        "# \"...a password with an entropy of 42 bits would require 2^(42) (4,398,046,511,104) \n",
        "#  attempts to exhaust all possibilities during a brute force search\"\n",
        " \n",
        "# Read more about it here: (https://en.wikipedia.org/wiki/Password_strength#Entropy_as_a_measure_of_password_strength, https://www.pleacher.com/mp/mlessons/algebra/entropy.html)\n",
        "from math import log\n",
        "\n",
        "special_chars = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '.', ',', '?', '/', '>', '<', '[', ']', '{', '}', '|', '\\\\', ';', ':','+', '=', '-', '_', ' ']\n",
        "character_classes = [\n",
        "    'abcdefghijklmnopqrstuvwxyz',\n",
        "    'ABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
        "    '0123456789',\n",
        "    special_chars\n",
        "]\n",
        "\n",
        "def entropy_bits(password):\n",
        "    if len(password) <= 1:\n",
        "        return 0\n",
        "\n",
        "    uniq_char_pool = []\n",
        "    uniq_test = (any(1 for c in password if c.islower()), \n",
        "                any(1 for c in password if c.isupper()), \n",
        "                any(1 for c in password if c.isdigit()), \n",
        "                any(1 for c in password if c in special_chars))\n",
        "\n",
        "    for i in range(4):\n",
        "        if uniq_test[i]:\n",
        "            uniq_char_pool += list(character_classes[i])\n",
        "\n",
        "    if len(uniq_char_pool)<=0:\n",
        "        return 0\n",
        "\n",
        "    return log(len(uniq_char_pool)**len(password), 2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets package these features in a function for easier future use\n",
        "def password_features(pass_df):\n",
        "    feats_df = pd.DataFrame(pass_df)\n",
        "    \n",
        "    # Password length is a feature that affects how easy it is to crack with brute force\n",
        "    # methods. Lets add that to our table.\n",
        "    feats_df['password_length'] = feats_df['password'].apply(lambda x: len(x))\n",
        " \n",
        "    # the number of character classes is also a feature. Each character class represents \n",
        "    # the pool of characters a hacker would have to test for each character in the string \n",
        "    feats_df['character_classes'] = feats_df['password'].apply(count_char_classes) \n",
        "    \n",
        "    # the presence of words in a password is also a feature. Passwords with words in them are easier to guess\n",
        "    feats_df['dictionary_presence'] = feats_df['password'].apply(\n",
        "      lambda x: 1 if has_word(x) else 0)\n",
        "    \n",
        "    # Now we'll count how many characters from each character class is present in the password\n",
        "    feats_df['letters'] = feats_df['password'].apply(lambda x: sum(1 for c in x if c.isalpha()))\n",
        "    feats_df['numbers'] = feats_df['password'].apply(lambda x: sum(1 for c in x if c.isdigit()))\n",
        "    feats_df['special_chars'] = feats_df['password'].apply(lambda x: sum(1 for c in x if c in special_chars))\n",
        "    feats_df['uppercase_characters'] = feats_df['password'].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
        "    feats_df['lowercase_characters'] = feats_df['password'].apply(lambda x: sum(1 for c in x if c.islower()))\n",
        "    \n",
        "    \n",
        "    # Finally, lets calculate entropy\n",
        "    feats_df['entropy'] = feats_df['password'].apply(entropy_bits)\n",
        "    \n",
        "    return feats_df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passwords_feats_df = password_features(passwords_df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's have a look at some basic statistics of the features"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "passwords_feats_df.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you look at the entropy values, you'll see that the average entropy is 36 bits (which requires about 2^(36) or 68719476736 attempts to exhaust all possibilities). Passwords in the 75 percentile (most of them) have an entropy value of around 42, which requires around 2^(42) (4,398,046,511,104) attempts. The password with the largest length (60 characters) has an entropy of 390, which is pretty would take a massive number of attempts (1.260864e+117 attempts). \n",
        "\n",
        "Lets see what that password looks like:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the password with the longest length from passwords_feats_df\n",
        "passwords_feats_df[passwords_feats_df['password_length'] == passwords_feats_df['password_length'].max()]['password'].values[0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doesn't look like a password at all! Its understandable to find junk like this in our dataset, since it contains brute force attempts. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets see how corelated the features are"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# shows how corelated the features are to each other\n",
        "passwords_feats_df.corr()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that almost every feature (dictionary_presence isn't) is positively corelated with entropy (increases when entropy increases). The character class has the greatest influence on entropy (0.92) followed by the password length."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A More Practical Dataset\n",
        "\n",
        "Remember, our dataset has passwords from brute force attempts to gain access to a publically accessible SSH port. The passwords in our dataset don't exactly reflect passwords people use, more so what hackers assume they would use for a server. Therefore, the dataset is a bit skewed towards popular passwords within that domain; that explains why you see passwords like 'password', 'admin', 'root', 'toor' and '123456' which are common default passwords. Attackers are hoping that these passwords were not updated so they can take advantage of that vulnerbility.\n",
        "\n",
        "Lets detour from here and take a look at actual passwords. Online, you can find password datasets from various data breaches. We'll use [this one](https://raw.githubusercontent.com/berzerk0/Probable-Wordlists/master/Real-Passwords/Top304Thousand-probable-v2.txt) which should have passwords that were actually used."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise:\n",
        "Load the dataset Top304Thousand_passwords.txt into a dataframe called real_passwords with column name 'password'. \n",
        "When you're done, print the first 5 rows of the dataframe"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# assuming the file is in the same directory as the junyper notebook\n",
        "\n",
        "# Exercise! load the dataset Top304Thousand_passwords.txt into a dataframe called real_passwords with column name 'password'\n",
        "# Print the dataframe"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assuming the file is in the same directory as the junyper notebook\n",
        "real_passwords = dict()\n",
        "\n",
        "with open(\"Top304Thousand_passwords.txt\") as f:\n",
        "    real_passwords['password'] = [line.rstrip() for line in f]\n",
        "\n",
        "real_passwords = pd.DataFrame(real_passwords)\n",
        "real_passwords.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets calculate the features for the new passwords"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "real_passwords = password_features(real_passwords)\n",
        "real_passwords.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let's look at some statistics about our realistic passwords dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "real_passwords.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_passwords.corr()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the real world passwords, numbers and uppercase characters are negatively correlated with entropy. Looking at the stats, this seems to be due to how infrequent uppercase characters and numbers appear in the passwords. Notice that the average entropy is still around 35-39 (roughly 274,877,906,944 attempts)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise!\n",
        "\n",
        "Draw a plot of your choice using our dataset. Feel free to tweak the dataset and visualize your findings, but ensure your tweaks are not persistent (assign to a new variable or use `inplace=False`)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib\n",
        "fig, ax = plt.subplots(figsize=(10,4))\n",
        "sns.set_context(\"notebook\")\n",
        "\n",
        "\n",
        "corr = real_passwords.drop('password', axis=1, inplace=False).corr()\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, cmap=cmap, vmax=1.0, center=0.0,\n",
        "            square=True, linewidths=.1,\n",
        "            cbar_kws={\"shrink\": .8})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%matplotlib\n",
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "sns.set_context(\"notebook\")\n",
        "\n",
        "ax = sns.lineplot(x=\"password_length\", y=\"entropy\", hue=\"character_classes\", data=real_passwords)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning\n",
        "\n",
        "Okay, lets make things a little interesting now. We have our formula for calculating entropy. which gives us an idea of the effort required to crack our passwords (using brute force method), but what if a we had a model that could predict this for us? Lets try to build this model!\n",
        "\n",
        "As we progress, bear in mind our features and their correlation with entropy."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Just for insights, this is a very simplified visualization of what machine learning does\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib\n",
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "sns.set_context(\"notebook\")\n",
        "\n",
        "sns.set(color_codes=True)\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "ax = sns.regplot(x=\"total_bill\", y=\"tip\", data=tips)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, lets extract the features from the dataset\n",
        "feats = real_passwords[['password_length', 'character_classes',\n",
        "       'dictionary_presence', 'letters', 'numbers', 'special_chars',\n",
        "       'uppercase_characters', 'lowercase_characters']]\n",
        "\n",
        "target = real_passwords['entropy']\n",
        "\n",
        "# Then lets start training the model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "# We'll need to split our training data from our test data\n",
        "x_train, x_test, y_train, y_test = train_test_split(feats, target, test_size=0.33,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Now we'll train the model to fit our data\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# And lets see how well our model's predictions are\n",
        "model.score(x_test, y_test)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That looks like a pretty good score! (99% predictible) How about we test the model and see."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame(y_test)\n",
        "predictions['predicted'] = model.predict(x_test)\n",
        "print(predictions.head())\n",
        "print('\\n')\n",
        "print(predictions.describe())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thats amazing results from the model! The predictions turn out to be very close to the actual entropy values.\n",
        "\n",
        " Try it yourself! \n",
        " Come up with a secure password and see how well it ranks. BE SURE NOT TO USE ANY PASSWORDS THAT YOU CURRENTLY USE FOR ANYTHING. THE COPS WILL COME GET YOU IF YOU DO. [DONT DO IT.](http://i.imgur.com/ZymDlls.gifv)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"change me\" and \"update me\" with your own secure password ideas and run the cell.\n",
        "my_test_passwords = pd.DataFrame([['change me'], ['update me']], columns=['password'])\n",
        "\n",
        "\n",
        "my_test_passwords = password_features(my_test_passwords)\n",
        "my_test_pass_feats = my_test_passwords[['password_length', 'character_classes',\n",
        "       'dictionary_presence', 'letters', 'numbers', 'special_chars',\n",
        "       'uppercase_characters', 'lowercase_characters']]\n",
        "my_test_passwords['predicted entropy'] = model.predict(my_test_pass_feats)\n",
        "my_test_passwords"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets Get Real! \n",
        "*puts shades on*\n",
        "\n",
        "Ooookay. Entropy numbers are nice, but they're meaningless if the password you use was similar or completely identitical to a leaked password. We can check each password against a rainbow table or cracking software, but that will require considerable effort...that some smart guys were kind enough to do for us and made it public :). \n",
        "\n",
        "So lets use their 'research-backed' password checker to add a few additional features to our dataset and model. We'll be using a library originally developed by Dropbox for determining password security. Its called zxcvbn (the 6 sequence of letters on the lowest row of the keyboard from left to right. Resembles one of the popular password patterns). You can find more info about it [here](https://github.com/dropbox/zxcvbn). The paper can be found [here](https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/wheeler) if you care about that stuff\n",
        "\n",
        "**cough** nerd **cough**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see what is available to us from the library\n",
        "from zxcvbn import zxcvbn\n",
        "zxcvbn('change me')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OOOOOO thats a lot of interesting stuff that we're going to ignore for now! You can take your time and look through the results above later. For now, we'll force on two metrics; the number of guesses and the offline show hashing time. \n",
        "\n",
        "With the additional info, we'll train a new model that would predict how long a passoword will take to crack."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# lets add the new features to our dataset \n",
        "# this is really intensive, so we'll need some help from our CPU core buddies\n",
        "# copied from https://stackoverflow.com/a/53135031 because I'm too tired for this\n",
        "from multiprocessing import  Pool\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "def parallelize(data, func, num_of_processes=8):\n",
        "    data_split = np.array_split(data, num_of_processes)\n",
        "    pool = Pool(num_of_processes)\n",
        "    data = pd.concat(pool.map(func, data_split))\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return data\n",
        "\n",
        "def run_on_subset(func, data_subset):\n",
        "    return data_subset.apply(func, axis=1)\n",
        "\n",
        "def parallelize_on_rows(data, func, num_of_processes=8):\n",
        "    return parallelize(data, partial(run_on_subset, func), num_of_processes)\n",
        "  \n",
        "  \n",
        "\n",
        "def apply_guess(df):\n",
        "  return zxcvbn(df['password'])['guesses']\n",
        "\n",
        "def apply_crack(df):\n",
        "  return zxcvbn(df['password'])['crack_times_seconds']['offline_slow_hashing_1e4_per_second']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CAUTION: This code will take really long and might make your computer really hot/drain battery\n",
        "# real_passwords['guesses'] = parallelize_on_rows(real_passwords, apply_guess)\n",
        "# real_passwords['crack_time'] = parallelize_on_rows(real_passwords, apply_crack)\n",
        "\n",
        "# Below, I save the results to a file so we don't need to spend minutes crunching the numbers again *bleh*\n",
        "#real_passwords.to_csv('real_passwords_with_guesses.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# I've provided the above changes in a file to save time. Please use that file. If you wish to crunch the numbers manually, may your PC rest in peace.\n",
        "real_passwords = pd.read_csv('real_passwords_with_guesses.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_passwords.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# And very quickly, look at the statistics!\n",
        "# IF you crunched the numbers manually, you need to uncomment the two lines below and run them\n",
        "# real_passwords['guesses'] = pd.to_numeric(real_passwords['guesses'])\n",
        "# real_passwords['crack_time'] = pd.to_numeric(real_passwords['crack_time'])\n",
        "\n",
        "real_passwords.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = real_passwords.drop('password', axis=1, inplace=False).corr()\n",
        "corr"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, cmap=cmap, vmax=1.0, center=0.0,\n",
        "            square=True, linewidths=.1,\n",
        "            cbar_kws={\"shrink\": .8})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like things are gonna be weird from that heatmap. Lets see what happens."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# and lets train a new model\n",
        "\n",
        "feats2 = real_passwords[['password_length', 'character_classes',\n",
        "       'dictionary_presence', 'letters', 'numbers', 'special_chars',\n",
        "       'uppercase_characters', 'lowercase_characters', 'entropy', 'guesses']]\n",
        "\n",
        "target2 = real_passwords['crack_time']\n",
        "\n",
        "# Then lets start training the model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model2 = LinearRegression()\n",
        "\n",
        "# We'll need to split our training data from our test data\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(feats2, target2, test_size=0.33,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Now we'll train the model to fit our data\n",
        "model2.fit(x_train2, y_train2)\n",
        "\n",
        "# And lets see how well our model's predictions are\n",
        "model2.score(x_test2, y_test2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HOLY MOLY BREDDA\n",
        "\n",
        "What is that? a 100% predictability score? As much as I want to brag about that (and i really do ;) ), I'm a little skeptical now. Lets do some tests and see what it spits out."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2 = pd.DataFrame(y_test2)\n",
        "predictions2['predicted'] = model2.predict(x_test2)\n",
        "print(predictions2.head())\n",
        "print('\\n')\n",
        "print(predictions2.describe())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh naw, that prediction might be too good. Our model probably overfitted the dataset. To find out, lets introduce some really new data (data from YOU) and we'll see if this consistency stays the same. \n",
        "\n",
        "If it does, awesome! If not, this model ain't it chief."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"change me\" and \"update me\" with your own secure password ideas and run the cell. \n",
        "# If you want to add more passwords, feel free to load your dataset manually or add an array with your password to the parent array [\"like this\"]\n",
        "my_test_passwords2 = pd.DataFrame([['change me'], ['update me'], ['password']], columns=['password'])\n",
        "\n",
        "\n",
        "# Our algorithm determines guesses and crack time again\n",
        "my_test_passwords2['guesses'] = parallelize_on_rows(my_test_passwords2, apply_guess).drop(columns='password')\n",
        "\n",
        "my_test_passwords2['crack_time'] = parallelize_on_rows(my_test_passwords2, apply_crack).drop(columns=['password', 'guesses'])\n",
        "\n",
        "# need to convert them to numbers before doing anything else\n",
        "my_test_passwords2['guesses'] = pd.to_numeric(my_test_passwords2['guesses'])\n",
        "my_test_passwords2['crack_time'] = pd.to_numeric(my_test_passwords2['crack_time'])\n",
        "\n",
        "# now we must generate the other features\n",
        "my_test_passwords2 = password_features(my_test_passwords2)\n",
        "\n",
        "# prepare the features for prediction\n",
        "my_test_pass_feats2 = my_test_passwords2[['password_length', 'character_classes',\n",
        "       'dictionary_presence', 'letters', 'numbers', 'special_chars',\n",
        "       'uppercase_characters', 'lowercase_characters', 'entropy', 'guesses']]\n",
        "\n",
        "# Here i switched the column order around so we can see the results better\n",
        "my_test_passwords2 = my_test_passwords2[['password','password_length', 'character_classes',\n",
        "       'dictionary_presence', 'letters', 'numbers', 'special_chars',\n",
        "       'uppercase_characters', 'lowercase_characters', 'entropy', 'guesses', 'crack_time']]\n",
        "\n",
        "\n",
        "my_test_passwords2['predicted crack time'] = model2.predict(my_test_pass_feats2)\n",
        "my_test_passwords2"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hope Yall Had Fun\n",
        "\n",
        "     .\"\".    .\"\",\n",
        "     |  |   /  /\n",
        "     |  |  /  /\n",
        "     |  | /  /\n",
        "     |  |/  ;-._\n",
        "     }  ` _/  / ;\n",
        "     |  /` ) /  /\n",
        "     | /  /_/\\_/\\\n",
        "     |/  /      |\n",
        "     (  ' \\ '-  |\n",
        "      \\    `.  /\n",
        "       |      |\n",
        "   jgs |      |\n",
        "\n",
        "\n",
        "[source](\n",
        "https://asciiart.website/index.php?art=logos%20and%20insignias/peace)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}